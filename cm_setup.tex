
%\subsubsection{Far-field detection} 
The far-field channel detection countermeasure is implemented according to the algorithm originally proposed in~\cite{Villalba2011} and described in Section~\ref{subsec:ffd}. The modulation indices are calculated frame-wise from the speech signal envelope which is approximated by the absolute value of the signal after down-sampling to 60~Hz.  The final modulation index is calculated by averaging over speech frames whose modulation index is above 0.75.  

%{\bfseries I struggle to see the correspondence with this description and the one in Section~\ref{subsec:ffd}.  There, there is no mention of average modulation index, where as here there is no mention of spectral ratio, low frequency ratio and the sub-band modulation indices. [AJ} Yes, it was unclear, I've corrected it.}

%\subsubsection{LBP setup} 
The LBP countermeasure is implemented using the toolkit provided by The University of Oulu\footnote{http://www.cse.oulu.fi/CMV/Downloads/LBPMatlab}.
Normalised acoustic features used for LBP analysis are composed of 51 coefficients: 16 LFCCs and energy plus their corresponding delta and delta-delta coefficients.  Analysis is applied only to speech frames and using only the $58$  uniform LBPs as originally described in~\cite{Ojala2002} and for speech processing in~\cite{Alegre2013a}.  %{\bfseries wasn't there some prior work by Chatlanni et al? [AJ] I couldn't find that name, sorry...}  
LBP histograms are created for all but the first and last rows, i.e., for $51 - 2 = 49$ rows.  Non-uniform LBPs are ignored thereby resulting in feature vectors of $58 \times 49 = 2842$ dimensions. 
%{\bfseries where does the 49 come from?  To what does a frame refer?  For me, a frame is time-dependent so I don't understand how the 49 is fixed??? [AJ] I have corrected the explaination - pls. check if now it's clear.}

% This is too much detail for something available elsewhere - but we could do with a least some mention of what is a uniform LBP
%Compared to the original implementation, we reduced the number of possible patterns according to the standard Uniform LBP approach. Uniform LBPs are the subset of $58$ patterns which contain at most two bitwise transitions from 0 to 1 or 1 to 0 when the bit pattern is traversed in circularly fashion.  As an example, the subset includes patterns $00000001$ and $00111100$ but not $00110001$.  As reported by~\cite{Ojala2002}, most patterns are naturally uniform and empirical evidence suggests that their use in many image recognition applications leads to better performance then the full set of uniform and non-uniform patterns.  We observed similar findings in our previous work~\cite{Alegre2013a} and thus decided to ignore pixels corresponding to any of the 198 non-uniform patterns.

%\subsubsection{Training the replay detectors} 
Both countermeasure algorithms are trained using a random subset of 1000 utterances from the NIST'05 dataset which are treated as described in Section~\ref{subsec::evaluation::datasets} in order to generate suitable training data with various acoustic conditions.  %{\bfseries So there is some overlap here!  Wouldn't it have been better to use different speaker from NIST'04 or NIST'08? [AJ] The only potential overlap is that NIST'05 was also used to train TV matrix for IV/IV-PLDA, but we wrote that "independence between development and evaluation datasets is always respected". Anyway, if you think that this could work against us, we might not mention it when talking about TV training...}
Room and loudspeaker impulse responses (a lecture room, a staircase and a meeting room) different to those used for ASV experiments aims to minimise countermeasure over-fitting.
%   of replay attack. Therefore we emulated the following environment:
%\begin{itemize}
%\item a lecture room, with concrete walls, glass windows and a parquet;
%\item a staircase, with concrete walls and steps;
%\item a meeting room, with concrete walls, glass windows and a carpet.
%\end{itemize}
%Similarly to emulation of replay attack, the corresponding impulse responses were taken from the AIR database. To train the far-field recording detector, we also needed to emulate the replay device. 
%A single high-quality speaker impulse response was used for We chose a stand-alone speaker impulse response, different from the one used for replay attack emulation, to avoid overfitting to testing data. Original NIST'05 recordings were used to model the licit client access trials.

A Bayesian network classifier~\cite{Pearl1988} is learned to differentiate genuine data from spoofed data in the case of the far-field channel detection countermeasure.  This classifier uses a network of probabilistic dependencies between random variables.  In contrast, the AdaBoost M1 meta classifier~\cite{Freund1999} is used for the LBP countermeasure.  This classifier  uses other `weak' classifiers, in this case decision trees, and iteratively boosts their performance by exposing them to previously misclassified instances.  These two classifiers, both implemented using the Weka toolkit~\cite{Weka}, returned the best results in each case for an area-under-the-ROC metric. %Having been trained, both classifiers were applied to detect replay attacks in both spoofing accesses and licit client trials.


For evaluation, countermeasures are used independently from ASV systems, similarly to the protocol used, e.g., in the ASVspoof 2015 evaluation~\cite{Wu2015} (which does not include replay attacks).  There are 1352 genuine trials and 8112 replay attacks, using various replay hardware and acoustic environments.  
%We ignored the anechoic chamber case, as it is not likely in a real life scenario.  
In a second set of experiments, countermeasures are integrated with ASV as in~\cite{Alegre2013a}. In this case, the countermeasure threshold is set heuristically to minimise the EER of the ASV system. Trials classified as spoofs are assigned an arbitrarily low score and are thereby rejected automatically.
