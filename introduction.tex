
% COMMENT: you should refer to presentation attacks somewhere

Spoofing refers to the presentation of a falsified or manipulated sample 
to the sensor of a biometric system in order to provoke a high score and 
thus illegitimate verification.
In recent years, the automatic speaker verification (ASV) community has 
started to investigate spoofing and countermeasures 
actively~\cite{interspeechSpecialSession, Wu2014a}. 
A growing 
body of independent work has now demonstrated the vulnerability of ASV 
systems to spoofing through 
replayed speech~\cite{Lindberg1999,Villalba2010},
impersonation~\cite{Blomberg2004,Farrus2008}, voice 
conversion~\cite{Perrot2005, Pellom1999}, speech 
synthesis~\cite{Masuko1999, Leon2010} and attacks with non-speech, 
artificial, tone-like signals~\cite{Alegre2012b}.

Common to the bulk of previous work is a focus on attacks 
which require either specific skills, e.g.~impersonation, or high-level 
technology, e.g.~speech synthesis and voice conversion. 
Only replay attacks can be performed with ease, requiring no specialist 
expertise nor equipment.  Since they are the most easily 
implemented, it is natural to assume that replay attacks will be the 
most commonly encountered in practice.  Nonetheless, the threat of 
replay attacks has not been quantified using large, standard 
datasets and hence never compared to that of other attacks which, have 
received considerably greater attention in the literature.
With replay attacks being considerably the easiest to implement
and with discreet, high quality audio equipment now available to the masses,
replay attacks also merit attention.
This paper accordingly aims to assess ASV vulnerabilities 
to replay attacks using the same ASV systems and base corpora used in 
previous assessments involving voice conversion and speech synthesis 
spoofing attacks.  In addition, the paper investigates the effectiveness of 
new countermeasures which aim to distinguish between genuine and replayed speech.  


============

To be merged with the above:

While a great deal of attention has been paid to medium- and high-effort spoofing attacks (reviews of which can be found in~\cite{Wu2014a,handbookChapter}), only few studies have addressed replay.  
The work in~\cite{Lindberg1999} assessed the vulnerabilities of an HMM-based, text-dependent ASV system with concatenated digits.  
While results showed that replay attacks are highly effective, experiments were conducted with data collected from only two speakers.
The work in~\cite{Villalba2010} investigated replay using recordings which were collected with close-talk or far-field microphones and then replayed over an analogue or digital telephony channel. 
The work was conducted with a similarly small corpus with five speakers and showed that a joint factor analysis (JFA) ASV system was vulnerable to replay attacks -- the FAR at the EER threshold increased from 1\% to almost 70\%. The authors in~\cite{Wu2014} investigated a text-dependent ASV system exposed to speech played back from a laptop. Using the RSR2015 corpus the authors showed that the EER increased from around 4\% to more than 20\%.

==========

The paper is organised as follows.  Section~2 describes speech synthesis and voice conversion spoofing attacks with a comparison to replay attacks. Section~3 presents previous and ongoing work to develop countermeasures against replay attacks, including our own work using the local binary pattern analysis of speech spectrograms.  A common experimental framework for the assessment of both vulnerabilities and countermeasures is presented in Section~4. Results are presented in Section~5 and our conclusions and ideas for future works are presented in Section~6.
