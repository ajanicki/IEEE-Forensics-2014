
Spoofing, also known as a presentation attack, refers to the projection of a falsified or manipulated sample 
to the sensor of a biometric system in order to provoke a high score and 
thus illegitimate verification.
In recent years the automatic speaker verification (ASV) community has 
started to investigate spoofing and countermeasures 
actively~\cite{interspeechSpecialSession, Wu2014a}. 
A growing 
body of independent work has demonstrated the vulnerability of ASV 
systems to spoofing through 
replayed speech~\cite{Lindberg1999,Villalba2010},
impersonation~\cite{Blomberg2004,Farrus2008}, voice 
conversion~\cite{Perrot2005, Pellom1999}, speech 
synthesis~\cite{Masuko1999, Leon2010} and attacks with non-speech, 
artificial, tone-like signals~\cite{Alegre2012a,Alegre2012b}.

Common to the bulk of previous work is a focus on attacks 
which require either specific expertise, e.g.~impersonation, or high-level 
technology, e.g.~speech synthesis and voice conversion. 
Only replay attacks can be performed with ease, requiring neither specific 
expertise nor sophisticated equipment; they are easily 
implemented %and while ignoring potential differences in efficacy, 
with discreet, high-quality audio equipment, now available to the masses.
Accordingly, it is reasonable to assume that replay attacks represent a tangible threat and that they will be the most prolific
in practice.  
%Nonetheless, the threat of 
%replay attacks has not been quantified using large, standard 
%datasets and hence never compared to that of the comparatively higher-effort
%attacks which have received considerably greater attention in the
%literature~\cite{Wu2014a,handbookChapter}.
%With replay attacks being considerably the easiest to implement
%
%replay attacks also merit attention.

Only few studies have addressed replay.  
The work in~\cite{Lindberg1999} assessed the vulnerabilities of a hidden Markov model (HMM) based, text-dependent ASV system using concatenated digits.  
While results showed that replay attacks are highly effective, experiments were conducted with data collected from only two speakers.
The work in~\cite{Villalba2010} investigated replay using recordings collected with close-talk or far-field microphones which are then replayed over an analogue or digital telephony channel. 
The work was conducted with data collected from five speakers and demonstrated the vulnerability of a joint factor analysis (JFA) ASV system; the false acceptance rate (FAR) at the equal error rate (EER) threshold increased from 1\% to almost 70\%. 
The authors in~\cite{Wu2014} investigated a text-dependent 
ASV system which was subjected to speech replayed using a laptop computer. 
Using the large, standard and publicly available RSR2015 corpus, this work showed that the EER for an HMM system increased from approximately 4\% to more than 20\%. %Unfortunately, none of the authors of the above papers gave any information about the acoustic conditions used in their experiments.

{\bfseries The new work MUST be referenced here, but this refers to the missing references published PRIOR to our paper, not those published afterwards. [AJ] None of these reported any vulnerability assessment.}

%%{\bfseries Can you say something further about the thoroughness of the assessments in terms of the number of replay conditions?  Do they all, for example, use only a single replay environment?  It's about trying to identify the new contribution of this work.}  OK - I see the edits but, on reflection, they were perhaps a little dismissive of the past work.  We can't risk insulting these authors who might be reviewers.

Missing from the literature, however, is a reliable comparative assessment 
of replay attacks to speech synthesis and voice conversion using large, 
standard databases and using a representative range of replay scenarios. 
Such a study is needed in order to help prioritise future work to develop
countermeasures for the protection of ASV from spoofing.
While well-intentioned, the work concerning speech synthesis and voice conversion attacks 
(including that of the authors), may have over-exaggerated the threat given that
only few people have the necessary capabilities to implement them.  Meanwhile, 
without appropriate countermeasures, ASV systems may remain vulnerable to replay 
attacks which are implemented much more easily. 
This paper accordingly aims to assess ASV vulnerabilities 
to replay attacks using the same ASV systems and corpora used in 
previous assessments involving speech synthesis and voice conversion.  In addition, the paper investigates the effectiveness of 
new countermeasures which aim to distinguish between genuine and replayed speech. 

% no - this is not the place to mention this.  It will need to be added in future work or conclusions sections.
%{\bfseries A recent study~\cite{Ergunay2015}, published after the current article was submitted, presents a decent comparison of four kinds of replay attacks, three types of speech synthesis attacks and three types of voice conversion attacks (all forming a corpus named AVspoof), challenging two types of ASV systems. We believe that this article, by using additional ASV systems, multiple replay configurations and in addition, by describing two countermeasures, will provide complementary value to the results shown in~\cite{Ergunay2015}. } 

The paper is organised as follows.  Section~\ref{sec::algorithms} describes speech synthesis and voice conversion spoofing attacks with a comparison to replay attacks. Specific implementations used for the work reported here are also described. Section~\ref{sec::CMs} presents previous and ongoing work to develop countermeasures against replay attacks, including the authors' work using the local binary pattern analysis of speech spectrograms.  A common experimental framework for the assessment of both vulnerabilities and countermeasures is presented in Section~\ref{sec::evaluation}. Results are presented in Section~\ref{sec::results}.  Priorities for future work are discussed in Section~\ref{sec::future} followed by conclusions in Section~\ref{sec::conclusions}.
