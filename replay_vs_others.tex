\begin{table*}[!ht]
\renewcommand{\arraystretch}{1.3}
%\ninept
\begin{center}
    \begin{tabular}{ l | c c c c }
    \hline
     	 Attack & Na\"{i}ve impostor &  Replay & Voice conversion & Speech synthesis\\ 
    \hline
Input         & impostor speech  & target speech & impostor speech & text\\
Effort        & zero & low & medium-high & high\\
Effectiveness & low &  low-to-high & medium-high & high\\
 \hline
\hline
    \end{tabular}
    \caption{Comparison of four different attacks in terms of speech used,  required effort and effectiveness.}
		\label{tab::attacks}
   \end{center}
\end{table*}

This section describes speech synthesis, voice conversion and replay spoofing attacks and specific implementations.  In general, a spoofed speech signal $s(t)$ is generated using a speech signal $x(t)$ which is representative of another, target speaker.  Whereas the input to a speech synthesis system is a text string, that to voice conversion originates from a third speech signal of a source speaker (spoofer) $y(t)$.  



\subsection{Speech synthesis}
\label{ssec:spsyn}

There is a large variety of speech synthesis algorithms, such as formant~\cite{Klatt1980}, diphone~\cite{Moulines1990}, unit-selection~\cite{Hunt1996} and statistical parametric~\cite{Tokuda2000} based approaches, in addition to more recent deep-neural network architectures~\cite{Zen2013}.  Whatever the approach, the aim is to generate intelligible, natural speech for a given text string $c$. In the context of spoofing, a synthetic speech signal is generated according to:

\begin{equation}
s(t) = g_{x(t)}(c),
\label{eq:tts}
\end{equation}

\noindent where $g_{x(t)}$ denotes a text-to-speech mapping generated by a synthesis system with speech units or acoustic models extracted or learned from the speech signal of a target speaker $x(t)$.  Today's state-of-the-art, unit-selection and statistical parametric approaches to speech synthesis can learn the mapping function $g_{x(t)}$ from the adaptation of well-trained background models using only modest or even small quantities of speaker-specific adaptation data~\cite{Zen2007a}.  

Our approach to statistical parametric speech synthesis uses hidden Markov models following the approach described in~\cite{Yamagishi2009a}.  The specific implementation uses the HMM-based Speech Synthesis System (HTS)\footnote{http://hts.sp.nitech.ac.jp/} where speech signals are parametrised by STRAIGHT (Speech Transformation and Representation using Adaptive Interpolation of weiGHTed spectrum) features~\cite{Kawahara2001}, Mel-cepstrum coefficients and the logarithm of the fundamental frequency (log $F_{0}$) with their delta and delta-delta coefficients.  Acoustic spectral characteristics and duration probabilities are modelled using multispace distribution hidden semi-Markov models (MSD-HSMM)~\cite{Russell1985}.  Speaker dependent  excitation, spectral and duration models are adapted from corresponding independent models according to a speaker adaptation strategy referred to as constrained structural maximum a posteriori linear regression (CSMAPLR)~\cite{Yamagishi2009a}.  Finally, time domain signals are synthesised from windows of 25ms with a step size of 5ms using a vocoder based on Mel-logarithmic spectrum approximation (MLSA) filters~\cite{Imai1983}.  They correspond to STRAIGHT Mel-cepstral coefficients and are driven by a mixed excitation signal~\cite{Yoshimura2005} and waveforms reconstructed using the pitch synchronous overlap add (PSOLA) method.  

Full details of the HTS approach to speech synthesis can be found in~\cite{Yamagishi2009a,Yamagishi2009,Zen2007}.  The same system has been used extensively by other authors in the study of ASV spoofing, e.g.~\cite{can you add here some of the other references already included in the article which used it?,,,Ergunay2015,Wu2015}.





\subsection{Voice conversion}
\label{ssec:vconv}

Voice conversion has been used to explore ASV spoofing since the late 90s~\cite{Pellom1999}.  Among many others, one particularly effective approach to spoofing involves so-called Gaussian-dependent filtering~\cite{Matrouf2005}. Here, the spoofing signal $s(t)$ (or $S(f)$ in the spectral domain) is generated by filtering at the frame level the speech signal of a spoofer's source signal $y(t)$. In the spectral domain it can be represented as follows:

\begin{equation}
S(f) = \frac{\left|H_{x}(f)\right|}{\left|H_{y}(f)\right|}Y(f)
\label{eq:conversioneq}
\end{equation}

\noindent where $H_{x}(f)$ and $H_{y}(f)$ are the vocal tract transfer functions of the targeted speaker and the spoofer respectively.  $Y(f)$ is the spoofer's speech signal in the spectral domain whereas $S(f)$ denotes the result after voice conversion. A time-domain, converted  signal is recovered as follows:

\begin{equation}
s(t) = IFFT(\frac{\left|H_{x}(f)\right|}{\left|H_{y}(f)\right|})*y(t)
\label{eq:conversioneq_t}
\end{equation}

\noindent where * denotes convolution. As such, $y(t)$ is mapped or converted towards the target in a spectral-envelope sense, and is sufficient to overcome most ASV systems~\cite{Matrouf2005, Bonastre2006}.

$H_x(f)$ is determined from a set of two Gaussian mixture models (GMMs).  The first, denoted as the automatic speaker recognition (asr) model in the original work, is related to ASV feature space and is utilised for the calculation of a posteriori probabilities.  The second, denoted as the filtering (fil) model, is a tied model of linear predictive cepstral coding (LPCC) coefficients from which $H_x(f)$ is derived.  LPCC filter parameters are obtained according to:

\begin{equation}
x_{fil} = \sum\limits_{i=1}^{M}p(g_{asr}^{i}|y_{asr}) \mu_{fil}^{i}
\label{eq:EMit}
\end{equation}

\noindent where $p(g_{asr}^{i}|y_{asr})$ is the a posteriori probability of Gaussian component $g_{asr}^{i}$ given the frame $y_{asr}$ and $\mu_{fil}^{i}$ is the mean of component $g_{fil}^{i}$ which is tied to $g_{asr}^{i}$.  $H_{x}(f)$ is estimated from $x_{fil}$ using an LPCC-to-LPC transformation and a time-domain signal is synthesised from converted frames with a standard overlap-add technique.  

Full details of the Gaussian-dependent filtering approach to voice conversion can be found in~\cite{Matrouf2005, Bonastre2006, Bonastre2007}.  These works, by other authors, in addition to the authors' own past work~\cite{Alegre2012a,Alegre2013,Alegre2013a} show that this particular approach is among the most effective in terms of spoofing~\cite{Wu2014a}.



\subsection{Replay}
\label{ssec:replay}

Replay attacks are an example of low-effort spoofing; they require simply the replaying of a previously captured speech signal.  
In the absence of suitable countermeasures and considering the widespread availability of consumer devices with high-quality sound systems, replay attacks can typically be realised with ease.  Furthermore, used either directly, or through the cutting and pasting of short speech intervals, replayed speech has potential to overcome both text-dependent and text-independent ASV systems.  Even though the processes of recording and replaying introduce additive acoustic and convolutive channel and transducer noise, these effects can be attenuated by noise and other intersession (channel) variability compensation techniques common to most modern ASV systems.  These factors point towards the tangible threat posed by replay attacks.

Ignoring ambient noise in the acoustic environment (which is in any case not specific to the replay spoofing scenario), replayed speech can be represented as:


\begin{equation}
s(t) = x(t)*h(t),
\label{eq:replay}
\end{equation}


\noindent where * again denotes convolution.  The composite replay effects denoted by $h(t)$ include the impulse responses of capture and replay hardware in addition to those of the recording and replay environments.  It is composed of:


\begin{figure}
	\includegraphics[width=1\linewidth]{Figs/replay.png}
	\caption{A schematic diagram of the assumed replay attack configuration. %{\bfseries <<< Increase font sizes in the figure >>>}%
}
	\label{fig::Replay}
\end{figure}

\begin{equation}
h(t) = \mathrm{mic}(t) * a(t) * \mathrm{spk}(t) * b(t),
\label{eq::playback}
\end{equation}


\noindent where $\mathrm{mic}(t)$ and $\mathrm{spk}(t)$ are impulse responses of the microphone and the speaker, respectively, and where $a(t)$ and $b(t)$ are the respective impulse responses of the recording and replay environments.  This scenario is illustrated in Fig.~\ref{fig::Replay}.  Replay attacks may thus be emulated through the convolution of a source signal $s(t)$ with typical impulse responses representing the different replay components.

Since an inordinately large number of different impulse responses would be needed to emulate representative replay attacks using Equation~\ref{eq:replay}, a simplification can be applied to reduce the number of impulse responses.  Since typical loudspeaker responses deviate more so from a regular impulse than typical microphone responses, and thus dominate Equation~\ref{eq::playback}, $\mathrm{mic}(t)$ can be safely ignored.  Furthermore, since $a(t)$ and $b(t)$ are similar in nature, a reasonable study can be achieved by considering only one.  Thus:

\begin{equation}
h(t) \simeq \mathrm{spk}(t) * b(t)
\label{eq::playbacksimplified}
\end{equation}

Equation~\ref{eq::playbacksimplified} represents a worst-case scenario where the spoofer obtains a high quality recording of the target speaker's voice, with no recording artefacts.  In this case, only replay components are considered and are the only means by which a replay attack can be detected.



\subsection{Qualitative comparison}
\label{sec::algorithms::comparison}



Replay, voice conversion and speech synthesis spoofing are forms of \emph{concerted-effort} impostor attacks, as opposed to the na\"{i}ve or \emph{zero-effort} impostor attacks normally used to assess ASV system performance.  A qualitative comparison of all four is illustrated in Table~\ref{tab::attacks}, ordered by the level of effort or expertise needed to implement each attack~\cite{Wu2014a}. 

Compared to na\"{i}ve impostor attacks, replay attacks require slightly increased effort; they require recording and replaying. Voice conversion and speech synthesis attacks require specialised, often complex algorithms, in addition to any recording hardware to collect, analyse and parametrise the target and any other auxiliary speech data.  They belong to a class of higher-effort spoofing attacks.  While voice conversion is based upon the conversion of one speech signal to another, speech synthesis converts a text string to a speech signal, which requires a comparatively higher level of effort or expertise.

One may reasonably suppose that the effectiveness of each attack is correlated with the level of effort involved in their implementation; the higher the effort, the more effective the algorithm and hence the greater the impact on ASV performance.  Replay attacks are then assumed to pose only a low threat.  {\bfseries This assumption would be supported by some of the earlier, related work, i.e. [AJ] CAN'T FIND any suitable reference here :(.}  However, the work in~\cite{Wu2014,Alegre2014} suggests the contrary, showing that replay attacks pose a significant threat, being effective in overcoming an ASV system while being the most easily implemented spoofing attack.  This paper investigates these contradictory findings and compares objectively the threat of replay spoofing to those of speech synthesis and voice conversion.
